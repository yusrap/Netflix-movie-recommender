{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b892588",
   "metadata": {},
   "source": [
    "## Import all Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as tf_idf\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=pd.read_csv('netflix_titles.csv') #read in the netflix file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape #dataset has seven columns, and 8807 movies(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b445ea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c52fa0c",
   "metadata": {},
   "source": [
    "## Preprocessing Begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50528510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of columns that will be needed\n",
    "#show_id\n",
    "#type\n",
    "#title\n",
    "#cast\n",
    "#country\n",
    "#listed_in\n",
    "#description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc72968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns\n",
    "movies.drop(\"date_added\", axis=1, inplace=True)\n",
    "movies.drop(\"release_year\", axis=1, inplace=True)\n",
    "movies.drop(\"duration\", axis=1, inplace=True)\n",
    "movies.drop(\"rating\", axis=1, inplace=True)\n",
    "movies.drop('director',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e3dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.isnull().sum() #checking for null values in needed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=movies.dropna() #dropping missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd13d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.isnull().sum()#checking to make sure there are no null values anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a1597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61adbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies.iloc[0]['cast'])\n",
    "print(movies.iloc[0]['listed_in'])\n",
    "print(movies.iloc[0]['country'])\n",
    "print(movies.iloc[0]['description'])\n",
    "print(movies.iloc[0]['type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b6be8d",
   "metadata": {},
   "source": [
    "Since the columns are in string formats and are needed in the list data structure, I'll apply split to each of the columns so it returns list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['cast']=movies['cast'].apply(lambda x:x.split(',')) \n",
    "movies['listed_in']=movies['listed_in'].apply(lambda x:x.split(',')) \n",
    "movies['country']=movies['country'].apply(lambda x:x.split(','))\n",
    "movies['description']=movies['description'].apply(lambda x:x.split())\n",
    "movies['type']=movies['type'].apply(lambda x:x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cc6690",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies.iloc[0]['cast'])\n",
    "print(movies.iloc[0]['listed_in'])\n",
    "print(movies.iloc[0]['country'])\n",
    "print(movies.iloc[0]['description'])\n",
    "print(movies.iloc[0]['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11702809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to get the first three names of the cast members\n",
    "def get_three_people(obj):\n",
    "    three_people=[]\n",
    "    counter=0\n",
    "    for i in (obj):\n",
    "        if counter != 3:\n",
    "            three_people.append(i)\n",
    "            counter+=1\n",
    "        else:\n",
    "            break\n",
    "    return three_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a41b27",
   "metadata": {},
   "outputs": [],
   "source": [
    " movies['cast']=movies['cast'].apply(get_three_people) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba7070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the columns to look better\n",
    "movies=movies.rename(columns={'type':'Type','title':'Title','cast':'Cast','country':'Country','listed_in':'Genre','description':'Overview'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7454b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head() #Now we have it how we want but there are still some works to do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422d02c0",
   "metadata": {},
   "source": [
    "Since each of the rows are now in list format, I need to remove spaces between each words. So, 'Mary Berry' becomes 'MaryBerry'.\n",
    "This creates uniformity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764941c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['Genre']=movies['Genre'].apply(lambda x: [i.replace(\" \",\"\") for i in x]) \n",
    "movies['Cast']=movies['Cast'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
    "movies['Country']=movies['Country'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
    "movies['Type']=movies['Type'].apply(lambda x: [i.replace(\" \",\"\") for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e3b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now add all the useful features under a new column called Tag\n",
    "movies['Tags']=movies['Cast']+movies['Country']+movies['Genre']+movies['Overview']+movies['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Netflix_df=movies[['show_id','Title','Tags']] #creating a new dataframe with the new important columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e55e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Netflix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Netflix_df['Tags']=Netflix_df['Tags'].apply(lambda x:\" \".join(x)) #converting back to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "Netflix_df=Netflix_df.reset_index() #resets index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadaa441",
   "metadata": {},
   "outputs": [],
   "source": [
    "Netflix_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f257927",
   "metadata": {},
   "source": [
    "Creating a function that extracts the part of speech of a word and put it in the format a lemmatizer would take. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2132cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eedeb4",
   "metadata": {},
   "source": [
    "Now to lemmatize each of the words to the root word while also considering context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143f4d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(word):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(word,get_wordnet_pos(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0318387",
   "metadata": {},
   "outputs": [],
   "source": [
    "Netflix_df['Tags']=Netflix_df['Tags'].apply(lemmatizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c27106",
   "metadata": {},
   "source": [
    "A tf_idf vectorizer is used to convert words to vectors based on their frequency and importance.Fit transform will basically fit the words into what we've set for tfidf and the toarray returns an array of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a533a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=tf_idf(max_features=4000,stop_words='english',lowercase=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83761830",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors=vectorizer.fit_transform(Netflix_df['Tags']).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b11884",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors.shape #this shows for 7305 movies, there are 4000 features(words) each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f3050",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()#this shows each of the features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf0cb9",
   "metadata": {},
   "source": [
    "## and that's all with preprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c80c86e",
   "metadata": {},
   "source": [
    "The cosine similarity will measure the similarity between each feature words and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity=cosine_similarity(vectors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b1479",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bdcd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(similarity[3],reverse=True) #this shows the cosine similarity of the 4th movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e21f23b",
   "metadata": {},
   "source": [
    "Now is time to write the recommendation function. The function takes a Title argument and checks with the dataset where the index of the title falls. it uses the index to bring a list of the movie's similarity score(compared to other movies). The scores are arranged in descending order and the first 10 are sliced. The Titles are then retrieved from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c3fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(Title): \n",
    "    movie_index=Netflix_df[Netflix_df['Title']==Title].index[0] \n",
    "    distances=similarity[movie_index] \n",
    "    movies_list=sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:10]\n",
    "    for i in movies_list:\n",
    "        print(Netflix_df.iloc[i[0]].Title) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ee3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation(\"Khoobsurat\") #up and working!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a239db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Netflix_df.to_dict(),open('Netflix_dict.pkl','wb')) #Now to deploy locally. Use pickle to dump files so that you\n",
    "#can load them later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf406e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities=pickle.dump(similarity,open('similarity.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb026440",
   "metadata": {},
   "source": [
    "## The END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af56f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
